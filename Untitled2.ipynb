{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"__main__\", line 31, in __main__.bag_of_bigrams_words\n",
      "Failed example:\n",
      "    bag_of_bigrams_words(['the', 'quick', 'brown', 'fox'])\n",
      "Expected:\n",
      "    {'brown': True, ('brown', 'fox'): True, ('the', 'quick'): True, 'quick': True, ('quick', 'brown'): True, 'the': True, 'fox': True}\n",
      "Got:\n",
      "    {'the': True, 'quick': True, 'brown': True, 'fox': True, ('brown', 'fox'): True, ('quick', 'brown'): True, ('the', 'quick'): True}\n",
      "**********************************************************************\n",
      "File \"__main__\", line 23, in __main__.bag_of_non_stopwords\n",
      "Failed example:\n",
      "    bag_of_non_stopwords(['the', 'quick', 'brown', 'fox'])\n",
      "Expected:\n",
      "    {'quick': True, 'brown': True, 'fox': True}\n",
      "Got:\n",
      "    {'brown': True, 'quick': True, 'fox': True}\n",
      "**********************************************************************\n",
      "File \"__main__\", line 9, in __main__.bag_of_words\n",
      "Failed example:\n",
      "    bag_of_words(['the', 'quick', 'brown', 'fox'])\n",
      "Expected:\n",
      "    {'quick': True, 'brown': True, 'the': True, 'fox': True}\n",
      "Got:\n",
      "    {'the': True, 'quick': True, 'brown': True, 'fox': True}\n",
      "**********************************************************************\n",
      "File \"__main__\", line 16, in __main__.bag_of_words_not_in_set\n",
      "Failed example:\n",
      "    bag_of_words_not_in_set(['the', 'quick', 'brown', 'fox'], ['the'])\n",
      "Expected:\n",
      "    {'quick': True, 'brown': True, 'fox': True}\n",
      "Got:\n",
      "    {'brown': True, 'quick': True, 'fox': True}\n",
      "**********************************************************************\n",
      "4 items had failures:\n",
      "   1 of   1 in __main__.bag_of_bigrams_words\n",
      "   1 of   1 in __main__.bag_of_non_stopwords\n",
      "   1 of   1 in __main__.bag_of_words\n",
      "   1 of   1 in __main__.bag_of_words_not_in_set\n",
      "***Test Failed*** 4 failures.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from nltk.corpus import stopwords, reuters\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "\n",
    "def bag_of_words(words):\n",
    "    bag_of_words(['the', 'quick', 'brown', 'fox'])\n",
    "    {'quick': True, 'brown': True, 'the': True, 'fox': True}\n",
    "\t'''\n",
    "\treturn dict([(word, True) for word in words])\n",
    "\n",
    "def bag_of_words_not_in_set(words, badwords):\n",
    "\t'''\n",
    "\t>>> bag_of_words_not_in_set(['the', 'quick', 'brown', 'fox'], ['the'])\n",
    "\t{'quick': True, 'brown': True, 'fox': True}\n",
    "\t'''\n",
    "\treturn bag_of_words(set(words) - set(badwords))\n",
    "\n",
    "def bag_of_non_stopwords(words, stopfile='english'):\n",
    "\t'''\n",
    "\t>>> bag_of_non_stopwords(['the', 'quick', 'brown', 'fox'])\n",
    "\t{'quick': True, 'brown': True, 'fox': True}\n",
    "\t'''\n",
    "\tbadwords = stopwords.words(stopfile)\n",
    "\treturn bag_of_words_not_in_set(words, badwords)\n",
    "\n",
    "def bag_of_bigrams_words(words, score_fn=BigramAssocMeasures.chi_sq, n=200):\n",
    "\t'''\n",
    "\t>>> bag_of_bigrams_words(['the', 'quick', 'brown', 'fox'])\n",
    "\t{'brown': True, ('brown', 'fox'): True, ('the', 'quick'): True, 'quick': True, ('quick', 'brown'): True, 'the': True, 'fox': True}\n",
    "\t'''\n",
    "\tbigram_finder = BigramCollocationFinder.from_words(words)\n",
    "\tbigrams = bigram_finder.nbest(score_fn, n)\n",
    "\treturn bag_of_words(words + bigrams)\n",
    "\n",
    "def bag_of_words_in_set(words, goodwords):\n",
    "\treturn bag_of_words(set(words) & set(goodwords))\n",
    "\n",
    "def label_feats_from_corpus(corp, feature_detector=bag_of_words):\n",
    "\tlabel_feats = collections.defaultdict(list)\n",
    "\t\n",
    "\tfor label in corp.categories():\n",
    "\t\tfor fileid in corp.fileids(categories=[label]):\n",
    "\t\t\tfeats = feature_detector(corp.words(fileids=[fileid]))\n",
    "\t\t\tlabel_feats[label].append(feats)\n",
    "\t\n",
    "\treturn label_feats\n",
    "\n",
    "def split_label_feats(lfeats, split=0.75):\n",
    "\ttrain_feats = []\n",
    "\ttest_feats = []\n",
    "\t\n",
    "\tfor label, feats in lfeats.items():\n",
    "\t\tcutoff = int(len(feats) * split)\n",
    "\t\ttrain_feats.extend([(feat, label) for feat in feats[:cutoff]])\n",
    "\t\ttest_feats.extend([(feat, label) for feat in feats[cutoff:]])\n",
    "\t\n",
    "\treturn train_feats, test_feats\n",
    "\n",
    "def high_information_words(labelled_words, score_fn=BigramAssocMeasures.chi_sq, min_score=5):\n",
    "\tword_fd = FreqDist()\n",
    "\tlabel_word_fd = ConditionalFreqDist()\n",
    "\t\n",
    "\tfor label, words in labelled_words:\n",
    "\t\tfor word in words:\n",
    "\t\t\tword_fd[word] += 1\n",
    "\t\t\tlabel_word_fd[label][word] += 1\n",
    "\t\n",
    "\tn_xx = label_word_fd.N()\n",
    "\thigh_info_words = set()\n",
    "\t\n",
    "\tfor label in label_word_fd.conditions():\n",
    "\t\tn_xi = label_word_fd[label].N()\n",
    "\t\tword_scores = collections.defaultdict(int)\n",
    "\t\t\n",
    "\t\tfor word, n_ii in label_word_fd[label].items():\n",
    "\t\t\tn_ix = word_fd[word]\n",
    "\t\t\tscore = score_fn(n_ii, (n_ix, n_xi), n_xx)\n",
    "\t\t\tword_scores[word] = score\n",
    "\t\t\n",
    "\t\tbestwords = [word for word, score in word_scores.items() if score >= min_score]\n",
    "\t\thigh_info_words |= set(bestwords)\n",
    "\t\n",
    "\treturn high_info_words\n",
    "\n",
    "def reuters_high_info_words(score_fn=BigramAssocMeasures.chi_sq):\n",
    "\tlabeled_words = []\n",
    "\t\n",
    "\tfor label in reuters.categories():\n",
    "\t\tlabeled_words.append((label, reuters.words(categories=[label])))\n",
    "\t\n",
    "\treturn high_information_words(labeled_words, score_fn=score_fn)\n",
    "\n",
    "def reuters_train_test_feats(feature_detector=bag_of_words):\n",
    "\ttrain_feats = []\n",
    "\ttest_feats = []\n",
    "\t\n",
    "\tfor fileid in reuters.fileids():\n",
    "\t\tif fileid.startswith('training'):\n",
    "\t\t\tfeatlist = train_feats\n",
    "\t\telse: # fileid.startswith('test')\n",
    "\t\t\tfeatlist = test_feats\n",
    "\t\t\n",
    "\t\tfeats = feature_detector(reuters.words(fileid))\n",
    "\t\tlabels = reuters.categories(fileid)\n",
    "\t\tfeatlist.append((feats, labels))\n",
    "\t\n",
    "\treturn train_feats, test_feats\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\timport doctest\n",
    "\tdoctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
